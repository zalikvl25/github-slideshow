{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChatBot.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO8LIosIpQg33uGXBkV8JdJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zalikvl25/github-slideshow/blob/main/ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NCKras-DbLA"
      },
      "source": [
        "#Аринин бот\n",
        "\n",
        "import nltk\n",
        "import random\n",
        "import json\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCj63W7HDlhS"
      },
      "source": [
        "with open('/content/BIG_CONFIG_.json', 'r') as f:\n",
        "    BOT_CONFIG = json.load(f)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztgBRpX7CRJj"
      },
      "source": [
        "\n",
        "def match(text, example):#гибкая функция сравнения\n",
        "    return nltk.edit_distance(text, example) / len(example) < 0.3 if len(example) >0 else False\n",
        "\n",
        "def cleaner(text):#Функция чистки текста\n",
        "    cleaned_text = ''\n",
        "    for ch in text.lower():\n",
        "        if ch in 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя abcdefghijklmnopqrstuvwxyz':\n",
        "            cleaned_text = cleaned_text + ch\n",
        "    return cleaned_text\n",
        "\n",
        "def get_intent(text):#Функция определения интента текста\n",
        "    for intent in BOT_CONFIG['intents']:\n",
        "      if 'examples' in BOT_CONFIG['intents'][intent]:\n",
        "        for example in BOT_CONFIG['intents'][intent]['examples']:\n",
        "            if match(cleaner(text), cleaner(example)):\n",
        "                return intent\n",
        "        "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FaT3i62EQ5x"
      },
      "source": [
        "X=[]\n",
        "y=[]\n",
        "for intent in BOT_CONFIG['intents']:\n",
        "    if 'examples' in BOT_CONFIG['intents'][intent]:\n",
        "        X += BOT_CONFIG['intents'][intent]['examples']\n",
        "        y += [intent for i in range(len(BOT_CONFIG['intents'][intent]['examples']))]\n",
        "#Создаем обучающую выборку для ML-модели"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_0OZpaYIZdo"
      },
      "source": [
        "vectorizer = CountVectorizer(preprocessor=cleaner, ngram_range=(1,3), stop_words = ['а','и'])\n",
        "#Создаем векторайзер - объект для превращения текста в вектора"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYBlptoqKz3c"
      },
      "source": [
        "vectorizer.fit(X)\n",
        "X_vect = vectorizer.transform(X)\n",
        "#Обучаем векторайзер на нашей выборке"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfWdHu6zPFJo"
      },
      "source": [
        "X_train_vect, X_test_vect, y_train, y_test = train_test_split(X_vect, y, test_size = 0.3)\n",
        "#Разбиваем выборку на train и на test"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xet1GcV8VteB",
        "outputId": "9b14bcdd-ffc1-4910-9a00-4e43a5eeeddc"
      },
      "source": [
        "sgd = SGDClassifier() #Создаем модель\n",
        "sgd.fit(X_vect, y)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
              "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
              "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
              "              validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBA1bNDKV7YR",
        "outputId": "13348d86-30fe-460c-8671-ab452e556b13"
      },
      "source": [
        "sgd.score(X_vect, y) #Смотрим качество классификации"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8978328173374613"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ovr4QFdSXPPt"
      },
      "source": [
        "def get_intent_by_model(text):#Функция, определяющая интент текста с помощью ML-модели\n",
        "    return sgd.predict(vectorizer.transform([text]))[0]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Bp235TjXmYZ"
      },
      "source": [
        "def bot(text):#Функция бота\n",
        "    intent=get_intent(text)    #1. Попытаться понять намерения сравнением по Левинштейну\n",
        "    if intent is None:\n",
        "        intent = get_intent_by_model(text)   #2. Понять намерения с помощью ML-модели\n",
        "    return random.choice(BOT_CONFIG['intents'][intent]['responses']) "
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTz7ROlmDt_e"
      },
      "source": [
        "#question = ''\n",
        "#while question not in ['выход', 'выключайся', 'хватит!']:\n",
        "      #question=input()\n",
        "      #print(\"Бот: \" + bot(question))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RCOhm3e9Cy4"
      },
      "source": [
        "#!pip install python-telegram-bot --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hjdb6QjJ-AYG"
      },
      "source": [
        "import logging\n",
        "\n",
        "from telegram import Update\n",
        "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters, CallbackContext\n",
        "\n",
        "# Enable logging\n",
        "logging.basicConfig(\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO\n",
        ")\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "# Define a few command handlers. These usually take the two arguments update and\n",
        "# context. Error handlers also receive the raised TelegramError object in error.\n",
        "def start(update: Update, _: CallbackContext) -> None:\n",
        "    \"\"\"Send a message when the command /start is issued.\"\"\"\n",
        "    update.message.reply_text('Hi!')\n",
        "\n",
        "\n",
        "def help_command(update: Update, _: CallbackContext) -> None:\n",
        "    \"\"\"Send a message when the command /help is issued.\"\"\"\n",
        "    update.message.reply_text('Help!')\n",
        "\n",
        "\n",
        "def echo(update: Update, _: CallbackContext) -> None:\n",
        "    \"\"\"Echo the user message.\"\"\"\n",
        "\n",
        "    update.message.reply_text(bot(update.message.text))\n",
        "\n",
        "\n",
        "def main() -> None:\n",
        "    \"\"\"Start the bot.\"\"\"\n",
        "    # Create the Updater and pass it your bot's token.\n",
        "    updater = Updater(\"1796743771:AAGxgsPzCc2dT6GIsNJAnaN2fVzB8l4bQGg\")\n",
        "\n",
        "    # Get the dispatcher to register handlers\n",
        "    dispatcher = updater.dispatcher\n",
        "\n",
        "    # on different commands - answer in Telegram\n",
        "    dispatcher.add_handler(CommandHandler(\"start\", start))\n",
        "    dispatcher.add_handler(CommandHandler(\"help\", help_command))\n",
        "\n",
        "    # on noncommand i.e message - echo the message on Telegram\n",
        "    dispatcher.add_handler(MessageHandler(Filters.text & ~Filters.command, echo))\n",
        "\n",
        "    # Start the Bot\n",
        "    updater.start_polling()\n",
        "\n",
        "    # Run the bot until you press Ctrl-C or the process receives SIGINT,\n",
        "    # SIGTERM or SIGABRT. This should be used most of the time, since\n",
        "    # start_polling() is non-blocking and will stop the bot gracefully.\n",
        "    updater.idle()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bFlcKKS-FYh",
        "outputId": "9100c786-9c48-4cc3-f11e-e2d85380291f"
      },
      "source": [
        "main()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-28 13:15:22,484 - apscheduler.scheduler - INFO - Scheduler started\n",
            "2021-03-28 13:29:25,269 - telegram.ext.updater - INFO - Received signal 2 (SIGINT), stopping...\n",
            "2021-03-28 13:29:25,275 - apscheduler.scheduler - INFO - Scheduler has been shut down\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}